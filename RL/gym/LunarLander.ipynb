{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae48e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from IPython.display import Video\n",
    "import torch\n",
    "import numpy as np\n",
    "from agent import QLearningAgent,DQNAgent,REINFORCE,ActorCritic,A2C\n",
    "import cv2\n",
    "from torch.utils.tensorboard import SummaryWriter  # Import TensorBoard\n",
    "import wandb\n",
    "use_wandb = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c446833",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "def show_env(env):\n",
    "    frame = env.render()\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot(x,ylabel='Loss'):\n",
    "    # === Plot ===\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(range(len(x)), x)\n",
    "    plt.show()\n",
    "\n",
    "def test_agent(agent, env=\"LunarLander-v3\", num_envs=8, num_episodes=1000):\n",
    "    \"\"\"\n",
    "    并行测试智能体在多个环境中的表现，不进行学习和探索。\n",
    "    输入:\n",
    "        agent: 智能体对象，需实现 get_action 方法\n",
    "        num_envs: 并行环境数量\n",
    "        num_episodes: 总测试回合数\n",
    "    输出:\n",
    "        绘制奖励分布图\n",
    "        \"\"\"\n",
    "        # 这里必须是工厂函数列表\n",
    "    envs =  gym.make_vec(env, num_envs=num_envs, vectorization_mode=\"sync\") # 同步环境\n",
    "    total_rewards = []\n",
    "    episodes_per_env = num_episodes // num_envs\n",
    "    agent.eval()\n",
    "\n",
    "    for _ in range(episodes_per_env):\n",
    "        states, infos = envs.reset()\n",
    "        dones = [False] * num_envs\n",
    "        rewards = [0.0] * num_envs\n",
    "\n",
    "        while not all(dones):\n",
    "            actions, _, _ = agent.get_action(states)\n",
    "            next_states, step_rewards, terminated, truncated, infos = envs.step(actions)\n",
    "            for i in range(num_envs):\n",
    "                if not dones[i]:\n",
    "                    rewards[i] += step_rewards[i]\n",
    "                    dones[i] = terminated[i] or truncated[i]\n",
    "            states = next_states\n",
    "        total_rewards.extend(rewards)\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(total_rewards, bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('reward')\n",
    "    plt.ylabel('episodes')\n",
    "    plt.title(f'{num_episodes} episodes-reward distribution')\n",
    "    plt.show()\n",
    "    \n",
    "def save_video(agent, env, file_name):\n",
    "    frames = []\n",
    "    obs, infos = env.reset()\n",
    "    sum_reward = 0\n",
    "    agent.eval()\n",
    "    while True:\n",
    "        action, prob, _ = agent.get_action(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        obs = next_obs\n",
    "        sum_reward += reward\n",
    "\n",
    "        frame = env.render()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        cv2.putText(frame, f\"Reward: {sum_reward:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    # 保存为视频\n",
    "    imageio.mimsave(file_name, frames, fps=30)\n",
    "    Video(file_name, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afd1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('动作空间：', env.action_space)\n",
    "print('观察空间: ', env.observation_space) # 8个值的区间\n",
    "# 观察就是部分状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    frame = env.render()\n",
    "    frames.append(frame)\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "# 保存为视频\n",
    "imageio.mimsave('lunarlander.mp4', frames, fps=30)\n",
    "Video('lunarlander.mp4', embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = QLearningAgent(\n",
    "        state_size=8,\n",
    "        action_size=2,\n",
    "        device=device)\n",
    "agent.qnet.to(device)  # 模型转到GPU\n",
    "\n",
    "episodes = 1000\n",
    "loss_history = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()\n",
    "    total_loss, cnt = 0, 0\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    t = 0\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        action = agent.getAction(state)\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        loss = agent.update(state, action, reward, next_state, terminated or truncated)\n",
    "        state = next_state\n",
    "        t += 1\n",
    "    agent.epsilon_update()\n",
    "\n",
    "    writer.add_scalar('Loss/train', loss, episode)\n",
    "    writer.add_scalar('Reward/train', reward, episode)\n",
    "    writer.add_scalar('Episode Duration/train', t, episode)\n",
    "    writer.add_scalar('Epl/train', t, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac53a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('episode')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(range(len(loss_history)), loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f388a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存权重\n",
    "torch.save(agent.qnet.state_dict(), \"lunar_lander.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(\n",
    "    lr=0.0001,\n",
    "    epsilon=1,\n",
    "    epsilon_decay=0.995,\n",
    "    TAU=0.005,\n",
    "    batch_size=128,\n",
    "    buffer_size=10000,\n",
    "    action_size=4,\n",
    "    device=device,\n",
    "    use_cnn=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8951f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent.train()\n",
    "writer = SummaryWriter()\n",
    "episodes = 600\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    t = 0\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, Q = agent.get_action(state)\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        loss = agent.update(state, action, reward, next_state, done)\n",
    "        t += 1\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    agent.epsilon_update()\n",
    "    writer.add_scalar('Loss/train', loss, episode)\n",
    "    writer.add_scalar('Reward/train', total_reward, episode)\n",
    "    writer.add_scalar('Episode Duration/train', t, episode)\n",
    "    writer.add_scalar('Epsilon/train', agent.epsilon, episode)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c587cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save(\"models/dqn_lunar_lander.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load(\"models/dqn_lunar_lander.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d91fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent(agent,env=\"LunarLander-v3\",num_envs=128,num_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58603c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video(agent, env,'dqn_lunarlander.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccecf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = REINFORCE(\n",
    "    lr=0.001,\n",
    "    action_size=4)\n",
    "episodes=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(episodes):\n",
    "    state, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    sum_reward = 0\n",
    "\n",
    "    while not (terminated or truncated): \n",
    "        action, prob = agent.get_action(state)\n",
    "        next_state, reward, terminated, truncated, info = env.step(action.item())\n",
    "\n",
    "        agent.add(reward, prob)\n",
    "        state = next_state\n",
    "        sum_reward += reward\n",
    "\n",
    "    loss = agent.update()\n",
    "\n",
    "    if episode % 100 == 0:\n",
    "        print(\"episode :{}, total reward : {:.1f}, loss : {:.4f}\".format(episode, sum_reward, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.pi.state_dict(), \"models/reinforce_lunar_lander2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.pi.load_state_dict(torch.load(\"models/reinforce_lunar_lander2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent(agent,env=\"LunarLander-v3\",num_envs=128,num_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb26586",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'lr_pi': 0.001,\n",
    "    'lr_v': 0.0002,\n",
    "    'gamma': 0.98\n",
    "}\n",
    "agent = ActorCritic(\n",
    "    action_size=4,\n",
    "    device='cpu',\n",
    "    **hyperparams\n",
    ")\n",
    "# agent.train()\n",
    "writer = SummaryWriter(comment=\"ActorCritic\")\n",
    "writer.add_hparams(hyperparams, {})\n",
    "episodes = 600\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    t = 0\n",
    "    actor_loss = 0\n",
    "    critic_loss = 0\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done: \n",
    "        action, action_probs = agent.get_action(state)\n",
    "        next_state, reward,  terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        done = (terminated or truncated)\n",
    "        losses = agent.update(state, action, action_probs, reward, next_state, done)\n",
    "        state = next_state\n",
    "        actor_loss += losses['actor_loss']\n",
    "        critic_loss += losses['critic_loss']\n",
    "        total_reward += reward\n",
    "        t += 1\n",
    "\n",
    "    writer.add_scalar('Actor Loss/train', actor_loss, episode)\n",
    "    writer.add_scalar('Critic Loss/train', critic_loss, episode)\n",
    "    writer.add_scalar('Reward/train', total_reward, episode)\n",
    "    writer.add_scalar('Episode Duration/train', t, episode)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dda4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'agent': 'A2C',\n",
    "    'action_size': 4,\n",
    "    'device': device,\n",
    "    'lr': 7e-4,\n",
    "    'gamma': 0.99,\n",
    "    'max_grad_norm': 0.5,\n",
    "    'policy_coef': 1,\n",
    "    'value_coef': 0.5,\n",
    "    'entropy_coef': 0.5, # 鼓励模型探索，避免过早收敛到某个确定动作\n",
    "    'total_steps': 50_000,\n",
    "    'num_env': 128\n",
    "}\n",
    "agent = A2C(\n",
    "    **config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5bb5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    wandb.init(\n",
    "        project=\"LunarLander-v3\",\n",
    "        config=config,  # 直接传入你的 config 字典\n",
    "        name=\"A2C训练\"\n",
    "    )\n",
    "else:\n",
    "    writer = SummaryWriter(comment=\"A2C\")\n",
    "env_vec = gym.make_vec(\"LunarLander-v3\", num_envs=config['num_env'], vectorization_mode=\"sync\") # 同步环境向量，会打开autoreset模式\n",
    "states, infos = env_vec.reset()\n",
    "actor_loss = 0\n",
    "critic_loss = 0\n",
    "\n",
    "for step in range(config['total_steps']):\n",
    "    actions, action_probs, values = agent.get_action(states)\n",
    "    next_states, rewards, terminated, truncated, info = env_vec.step(actions)\n",
    "\n",
    "    done = np.logical_or(terminated, truncated)\n",
    "    losses = agent.update(states, actions, action_probs, values, rewards, next_states, done)\n",
    "\n",
    "    states = next_states\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.log({\n",
    "            'Actor Loss/train': actor_loss,\n",
    "            'Critic Loss/train': critic_loss,\n",
    "        }, step=step)\n",
    "    else:\n",
    "        writer.add_scalar('Actor Loss/train', losses['actor_loss'], step)\n",
    "        writer.add_scalar('Critic Loss/train', losses['critic_loss'], step)\n",
    "        writer.add_scalar('Entropy Loss/train', losses['entropy_loss'], step)\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.finish()\n",
    "else:\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c22144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_agent(agent,env=\"LunarLander-v3\",num_envs=128,num_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d937406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "save_video(agent, env,'a2c_lunarlander.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46869783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 97.1     |\n",
      "|    ep_rew_mean     | -206     |\n",
      "| time/              |          |\n",
      "|    fps             | 783      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.1        |\n",
      "|    ep_rew_mean          | -173        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005492553 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00441     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 815         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 2.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.7        |\n",
      "|    ep_rew_mean          | -164        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005209894 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.00493    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 338         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 916         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.5        |\n",
      "|    ep_rew_mean          | -157        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 352         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008184651 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 7.19e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 250         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    value_loss           | 614         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94.3         |\n",
      "|    ep_rew_mean          | -141         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 339          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077786883 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.0022      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 265          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    value_loss           | 625          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.4         |\n",
      "|    ep_rew_mean          | -144         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 331          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078061894 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | -5.33e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    value_loss           | 353          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 99.3         |\n",
      "|    ep_rew_mean          | -139         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 325          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061771898 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | -0.00924     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 229          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    value_loss           | 519          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 103          |\n",
      "|    ep_rew_mean          | -135         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 321          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060342457 |\n",
      "|    clip_fraction        | 0.0551       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -0.0421      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    value_loss           | 514          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | -126        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009151578 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.0733     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | -119        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008708101 |\n",
      "|    clip_fraction        | 0.0364      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 6.87e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.000992   |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 107          |\n",
      "|    ep_rew_mean          | -115         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059445687 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 1.43e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 139          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 261          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | -108        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006714754 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -0.0135     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    value_loss           | 538         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | -99.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009001309 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -0.000109   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 108          |\n",
      "|    ep_rew_mean          | -98.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062598856 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -0.000236    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00858     |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 110         |\n",
      "|    ep_rew_mean          | -99.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008280998 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 2.38e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 309         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 112         |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008092804 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.000149   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    value_loss           | 358         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 115          |\n",
      "|    ep_rew_mean          | -94.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034957367 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 4.62e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    value_loss           | 420          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 116          |\n",
      "|    ep_rew_mean          | -88.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016785173 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.0709       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 82.8         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 118          |\n",
      "|    ep_rew_mean          | -87.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 306          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007536364 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.0974       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 218          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 343          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 120          |\n",
      "|    ep_rew_mean          | -86.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 306          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043002805 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    value_loss           | 264          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 119        |\n",
      "|    ep_rew_mean          | -78.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 140        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00406198 |\n",
      "|    clip_fraction        | 0.0167     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.232      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 146        |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0025    |\n",
      "|    value_loss           | 310        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 118          |\n",
      "|    ep_rew_mean          | -70.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039953273 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 161          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 411          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 117          |\n",
      "|    ep_rew_mean          | -66.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 304          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050871572 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.288        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 149          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    value_loss           | 217          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 116          |\n",
      "|    ep_rew_mean          | -64.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 304          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047099544 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.216        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    value_loss           | 301          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 115          |\n",
      "|    ep_rew_mean          | -61.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 304          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053108097 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.288        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 116         |\n",
      "|    ep_rew_mean          | -61.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003931362 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.9        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 115         |\n",
      "|    ep_rew_mean          | -58.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009061722 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.9        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 116          |\n",
      "|    ep_rew_mean          | -57.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 303          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064219674 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 95.6         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 118          |\n",
      "|    ep_rew_mean          | -58          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 302          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075279945 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 122         |\n",
      "|    ep_rew_mean          | -57.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006716433 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 122         |\n",
      "|    ep_rew_mean          | -52.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004967685 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 124         |\n",
      "|    ep_rew_mean          | -50         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004323929 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 124          |\n",
      "|    ep_rew_mean          | -49.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021900588 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 133          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    value_loss           | 234          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | -49.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004807364 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 122         |\n",
      "|    ep_rew_mean          | -44.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004897833 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 121          |\n",
      "|    ep_rew_mean          | -39.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062067397 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 85.6         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00986     |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 128          |\n",
      "|    ep_rew_mean          | -39.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 300          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028435583 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.3         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 131         |\n",
      "|    ep_rew_mean          | -38.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006558533 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 131         |\n",
      "|    ep_rew_mean          | -37.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006565253 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.9        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 132         |\n",
      "|    ep_rew_mean          | -36.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006482387 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 135          |\n",
      "|    ep_rew_mean          | -32.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 299          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 279          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042955643 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 78.4         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00895     |\n",
      "|    value_loss           | 181          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | -31.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006122083 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 151         |\n",
      "|    ep_rew_mean          | -31.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009772499 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | -31.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006040367 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.4        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 139         |\n",
      "|    ep_rew_mean          | -29.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004719274 |\n",
      "|    clip_fraction        | 0.00586     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.5        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 139          |\n",
      "|    ep_rew_mean          | -31.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 297          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 316          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053825453 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 86.1         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00887     |\n",
      "|    value_loss           | 194          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 138         |\n",
      "|    ep_rew_mean          | -31.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006130076 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.3        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 137          |\n",
      "|    ep_rew_mean          | -32.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 297          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 330          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063844183 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 120          |\n",
      "|    ep_rew_mean          | -31.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 296          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065465807 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 81.9         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00826     |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f9b589c8340>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rbg_array\")\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, ent_coef=0.2)\n",
    "model.learn(total_timesteps=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffb22cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "rewards = []\n",
    "for episode in range(100):\n",
    "    total_rewards = 0\n",
    "    while True:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "        total_rewards += reward\n",
    "        if done:\n",
    "            rewards.append(total_rewards)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "815e04b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(rewards).flatten(), bins=30, color='skyblue', edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d7309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
